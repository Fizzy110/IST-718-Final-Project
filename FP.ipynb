{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "#data source: https://data.nber.org/data/vital-statistics-natality-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv file via spark way\n",
    "#create DF\n",
    "births = spark.read.csv('nat18.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- birth_place: string (nullable = true)\n",
      " |-- mothers_age: string (nullable = true)\n",
      " |-- fathers_age: string (nullable = true)\n",
      " |-- prental_care: string (nullable = true)\n",
      " |-- cigarettes_before_pregnancy: string (nullable = true)\n",
      " |-- cigarettes_1_trimester: string (nullable = true)\n",
      " |-- cigarettes_2_trimester: string (nullable = true)\n",
      " |-- cigarettes_3_trimester: string (nullable = true)\n",
      " |-- mothers_height: string (nullable = true)\n",
      " |-- bmi: string (nullable = true)\n",
      " |-- prepregnancy_weight: string (nullable = true)\n",
      " |-- delivery_weight: string (nullable = true)\n",
      " |-- weight_gain: string (nullable = true)\n",
      " |-- prepregnancy_diabetes: string (nullable = true)\n",
      " |-- gestational_diabetes: string (nullable = true)\n",
      " |-- prepregnancy_hypertension: string (nullable = true)\n",
      " |-- gestational_hypertension: string (nullable = true)\n",
      " |-- hypertension_eclampsia: string (nullable = true)\n",
      " |-- previous_preterm_birth: string (nullable = true)\n",
      " |-- infant_sex: string (nullable = true)\n",
      " |-- infant_live: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print the data schema\n",
    "births.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to filter our dataset to get rid of any unknown records\n",
    "#according to our user guide, 'U' means unknown\n",
    "births = births.filter((births.infant_live != 'U'))\n",
    "births = births.filter((births.prepregnancy_diabetes != 'U'))\n",
    "births = births.filter((births.gestational_diabetes != 'U'))\n",
    "births = births.filter((births.prepregnancy_hypertension != 'U'))\n",
    "births = births.filter((births.gestational_hypertension!= 'U'))\n",
    "births = births.filter((births.hypertension_eclampsia!= 'U'))\n",
    "births = births.filter((births.previous_preterm_birth!= 'U'))\n",
    "births = births.filter((births.fathers_age!= 99))\n",
    "births = births.filter((births.cigarettes_before_pregnancy!= 99))\n",
    "births = births.filter((births.cigarettes_1_trimester!= 99))\n",
    "births = births.filter((births.cigarettes_2_trimester!= 99))\n",
    "births = births.filter((births.cigarettes_3_trimester!= 99))\n",
    "births = births.filter((births.mothers_height!= 99))\n",
    "births = births.filter((births.bmi!= 99.9))\n",
    "births = births.filter((births.prepregnancy_weight!= 999))\n",
    "births = births.filter((births.delivery_weight!= 999))\n",
    "births = births.filter((births.weight_gain!= 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|infant_live|  count|\n",
      "+-----------+-------+\n",
      "|          Y|3224846|\n",
      "|          N|   2213|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count the frequency distribution of living cases\n",
    "births.groupby('infant_live').count().show()\n",
    "#It seems our dataset is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows: 3227059\n",
      "Count of distinct rows: 3227059\n"
     ]
    }
   ],
   "source": [
    "#Basical dataset statistical check\n",
    "#step1: if the dataset contains duplicate rows:\n",
    "print('Count of rows: {0}'.format(births.count()))\n",
    "print('Count of distinct rows: {0}'.format(births.distinct().count()))\n",
    "#the results show our dataset contains no same rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step2: check if the dataset contains missing values:\n",
    "bool(births.head(1)) #if the result is False，then the dataset has missing values，otherwise no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>mothers_age</th>\n",
       "      <th>fathers_age</th>\n",
       "      <th>cigarettes_before_pregnancy</th>\n",
       "      <th>cigarettes_1_trimester</th>\n",
       "      <th>cigarettes_2_trimester</th>\n",
       "      <th>cigarettes_3_trimester</th>\n",
       "      <th>mothers_height</th>\n",
       "      <th>bmi</th>\n",
       "      <th>prepregnancy_weight</th>\n",
       "      <th>delivery_weight</th>\n",
       "      <th>weight_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "      <td>3227059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>29.369372236454307</td>\n",
       "      <td>31.787807412259895</td>\n",
       "      <td>0.9047463960218887</td>\n",
       "      <td>0.536430229506185</td>\n",
       "      <td>0.4000633394059421</td>\n",
       "      <td>0.35471523762038437</td>\n",
       "      <td>64.14300017446226</td>\n",
       "      <td>27.021742335662797</td>\n",
       "      <td>158.3141612843149</td>\n",
       "      <td>187.8532930448436</td>\n",
       "      <td>29.630798817127296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>5.65609680246426</td>\n",
       "      <td>6.7945446000085346</td>\n",
       "      <td>4.268990604512946</td>\n",
       "      <td>3.0017986187169297</td>\n",
       "      <td>2.4669276997873477</td>\n",
       "      <td>2.3158727974928977</td>\n",
       "      <td>2.82244356691906</td>\n",
       "      <td>6.603225258403328</td>\n",
       "      <td>40.895831495380655</td>\n",
       "      <td>40.439737222800055</td>\n",
       "      <td>14.838047763424377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>50</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>78</td>\n",
       "      <td>69.9</td>\n",
       "      <td>99</td>\n",
       "      <td>400</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary         mothers_age         fathers_age cigarettes_before_pregnancy  \\\n",
       "0   count             3227059             3227059                     3227059   \n",
       "1    mean  29.369372236454307  31.787807412259895          0.9047463960218887   \n",
       "2  stddev    5.65609680246426  6.7945446000085346           4.268990604512946   \n",
       "3     min                  12                  11                           0   \n",
       "4     max                  50                  95                          98   \n",
       "\n",
       "  cigarettes_1_trimester cigarettes_2_trimester cigarettes_3_trimester  \\\n",
       "0                3227059                3227059                3227059   \n",
       "1      0.536430229506185     0.4000633394059421    0.35471523762038437   \n",
       "2     3.0017986187169297     2.4669276997873477     2.3158727974928977   \n",
       "3                      0                      0                      0   \n",
       "4                     98                     98                     98   \n",
       "\n",
       "      mothers_height                 bmi prepregnancy_weight  \\\n",
       "0            3227059             3227059             3227059   \n",
       "1  64.14300017446226  27.021742335662797   158.3141612843149   \n",
       "2   2.82244356691906   6.603225258403328  40.895831495380655   \n",
       "3                 36                13.0                 100   \n",
       "4                 78                69.9                  99   \n",
       "\n",
       "      delivery_weight         weight_gain  \n",
       "0             3227059             3227059  \n",
       "1   187.8532930448436  29.630798817127296  \n",
       "2  40.439737222800055  14.838047763424377  \n",
       "3                 100                   0  \n",
       "4                 400                  98  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step3: For numerical data, apply the describe() to get statistical summay.\n",
    "numerical = ['mothers_age', 'fathers_age', 'cigarettes_before_pregnancy','cigarettes_1_trimester'\n",
    "            ,'cigarettes_2_trimester','cigarettes_3_trimester','mothers_height','bmi'\n",
    "            ,'prepregnancy_weight','delivery_weight','weight_gain']\n",
    "desc = births.describe(numerical)\n",
    "desc.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering - covert categorical data to dummy variable\n",
    "import pyspark.sql.functions as fn\n",
    "#1.\n",
    "categ = births.select('infant_live').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "exprs = [fn.when(fn.col('infant_live') == Y,1).otherwise(0)\\\n",
    "            .alias(str(Y)) for Y in categ]\n",
    "births = births.select(exprs+births.columns)\n",
    "#drop useless columns and rename target column\n",
    "births = births.drop('N')\n",
    "births = births.drop('_c0')\n",
    "births = births.drop('infant_live')\n",
    "births = births.withColumnRenamed('Y','infant_live_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = births.withColumn('prepregnancy_diabetes_int',births['prepregnancy_diabetes']\n",
    "                          .cast(typ.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column prepregnancy_diabetes must be of type numeric but was actually of type string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ff5ad3aeb52f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                           outputCol = 'prepregnancy_diabetes_vec')\n\u001b[1;32m      9\u001b[0m \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'prepregnancy_diabetes_vec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'feature1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtest_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbirths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mbirths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prepregnancy_diabetes_int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Column prepregnancy_diabetes must be of type numeric but was actually of type string."
     ]
    }
   ],
   "source": [
    "#test cell - OneHotEncoding rather than hard coding:\n",
    "import pyspark.ml.feature as ft\n",
    "import pyspark.sql.types as typ\n",
    "from pyspark.ml import Pipeline\n",
    "#births = births.withColumn('prepregnancy_diabetes_int',births['prepregnancy_diabetes']\n",
    "                          #.cast(typ.IntegerType()))\n",
    "encoder = ft.OneHotEncoder(inputCol = 'prepregnancy_diabetes',\n",
    "                          outputCol = 'prepregnancy_diabetes_vec')\n",
    "ft = ft.VectorAssembler(inputCols = ['prepregnancy_diabetes_vec'],outputCol = 'feature1')\n",
    "test_pipe = Pipeline(stages=[encoder,ft]).fit(births)\n",
    "births.groupby('prepregnancy_diabetes_int').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "cat2 = births.select('prepregnancy_diabetes').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "expr2 = [fn.when(fn.col('prepregnancy_diabetes') == Y,1).otherwise(0)\\\n",
    "            .alias(str(Y)) for Y in cat2]\n",
    "births = births.select(expr2+births.columns)\n",
    "births = births.drop('N')\n",
    "births = births.drop('prepregnancy_diabetes')\n",
    "births = births.withColumnRenamed('Y','prepregnancy_diabetes_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\n",
    "cat3 = births.select('gestational_diabetes').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "expr3 = [fn.when(fn.col('gestational_diabetes') == Y,1).otherwise(0)\\\n",
    "            .alias(str(Y)) for Y in cat3]\n",
    "births = births.select(expr3+births.columns)\n",
    "births = births.drop('N')\n",
    "births = births.drop('gestational_diabetes')\n",
    "births = births.withColumnRenamed('Y','gestational_diabetes_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.\n",
    "cat4 = births.select('prepregnancy_hypertension').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "expr4 = [fn.when(fn.col('prepregnancy_hypertension') == Y,1).otherwise(0)\\\n",
    "            .alias(str(Y)) for Y in cat4]\n",
    "births = births.select(expr4+births.columns)\n",
    "births = births.drop('N')\n",
    "births = births.drop('prepregnancy_hypertension')\n",
    "births = births.withColumnRenamed('Y','prepregnancy_hypertension_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.\n",
    "cat5 = births.select('gestational_hypertension').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "expr5 = [fn.when(fn.col('gestational_hypertension') == Y,1).otherwise(0)\\\n",
    "            .alias(str(Y)) for Y in cat5]\n",
    "births = births.select(expr5 + births.columns)\n",
    "births = births.drop('N')\n",
    "births = births.drop('gestational_hypertension')\n",
    "births = births.withColumnRenamed('Y','gestational_hypertension_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.\n",
    "cat6 = births.select('hypertension_eclampsia').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "expr6 = [fn.when(fn.col('hypertension_eclampsia') == Y,1).otherwise(0)\\\n",
    "            .alias(str(Y)) for Y in cat6]\n",
    "births = births.select(expr6 + births.columns)\n",
    "births = births.drop('N')\n",
    "births = births.drop('hypertension_eclampsia')\n",
    "births = births.withColumnRenamed('Y','hypertension_eclampsia_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.\n",
    "cat7 = births.select('previous_preterm_birth').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "expr7 = [fn.when(fn.col('previous_preterm_birth') == Y,1).otherwise(0)\\\n",
    "            .alias(str(Y)) for Y in cat7]\n",
    "births = births.select(expr7 + births.columns)\n",
    "births = births.drop('N')\n",
    "births = births.drop('previous_preterm_birth')\n",
    "births = births.withColumnRenamed('Y','previous_preterm_birth_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.\n",
    "cat8 = births.select('infant_sex').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "expr8 = [fn.when(fn.col('infant_sex') == M,1).otherwise(0)\\\n",
    "            .alias(str(M)) for M in cat8]\n",
    "births = births.select(expr8 + births.columns)\n",
    "births = births.drop('F')\n",
    "births = births.drop('infant_sex')\n",
    "births = births.withColumnRenamed('M','infant_sex_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast data type:\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.types as typ\n",
    "births = births.withColumn(\"birth_place\", col(\"birth_place\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"mothers_age\", col(\"mothers_age\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"fathers_age\", col(\"fathers_age\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"prental_care\", col(\"prental_care\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"cigarettes_before_pregnancy\", col(\"cigarettes_before_pregnancy\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"cigarettes_1_trimester\", col(\"cigarettes_1_trimester\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"cigarettes_2_trimester\", col(\"cigarettes_2_trimester\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"cigarettes_3_trimester\", col(\"cigarettes_3_trimester\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"mothers_height\", col(\"mothers_height\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"bmi\", col(\"bmi\").cast(typ.FloatType()))\n",
    "births = births.withColumn(\"prepregnancy_weight\", col(\"prepregnancy_weight\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"delivery_weight\", col(\"delivery_weight\").cast(typ.IntegerType()))\n",
    "births = births.withColumn(\"weight_gain\", col(\"weight_gain\").cast(typ.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|infant_sex_encoded|  count|\n",
      "+------------------+-------+\n",
      "|                 1|1650185|\n",
      "|                 0|1576874|\n",
      "+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add one more pairplot\n",
    "births.groupby('infant_sex_encoded').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#infant sex and infant live case\n",
    "ax = sns.pairplot(births.toPandas()[['infant_live_encoded','infant_sex_encoded']])\n",
    "ax.fig.suptitle(\"Vital Data Smoking Pair Plot\", y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mother's age and smoking before pregnancy\n",
    "ax = sns.pairplot(births.toPandas()[['mothers_age','cigarettes_before_pregnancy']])\n",
    "ax.fig.suptitle(\"Vital Data Smoking Pair Plot\", y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- infant_sex_encoded: integer (nullable = false)\n",
      " |-- previous_preterm_birth_encoded: integer (nullable = false)\n",
      " |-- hypertension_eclampsia_encoded: integer (nullable = false)\n",
      " |-- gestational_hypertension_encoded: integer (nullable = false)\n",
      " |-- prepregnancy_hypertension_encoded: integer (nullable = false)\n",
      " |-- gestational_diabetes_encoded: integer (nullable = false)\n",
      " |-- prepregnancy_diabetes_encoded: integer (nullable = false)\n",
      " |-- infant_live_encoded: integer (nullable = false)\n",
      " |-- birth_place: integer (nullable = true)\n",
      " |-- mothers_age: integer (nullable = true)\n",
      " |-- fathers_age: integer (nullable = true)\n",
      " |-- prental_care: integer (nullable = true)\n",
      " |-- cigarettes_before_pregnancy: integer (nullable = true)\n",
      " |-- cigarettes_1_trimester: integer (nullable = true)\n",
      " |-- cigarettes_2_trimester: integer (nullable = true)\n",
      " |-- cigarettes_3_trimester: integer (nullable = true)\n",
      " |-- mothers_height: integer (nullable = true)\n",
      " |-- bmi: float (nullable = true)\n",
      " |-- prepregnancy_weight: integer (nullable = true)\n",
      " |-- delivery_weight: integer (nullable = true)\n",
      " |-- weight_gain: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make a copy of the original data frame\n",
    "births_v1 = births\n",
    "births_v1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline model: logistic model\n",
    "import pyspark.ml.feature as ft\n",
    "from pyspark.ml import Pipeline\n",
    "feature_pipe = ft.VectorAssembler(inputCols=['birth_place', 'mothers_age', 'fathers_age', 'prental_care', 'cigarettes_before_pregnancy', 'cigarettes_1_trimester'\n",
    "                                    ,'cigarettes_2_trimester','cigarettes_3_trimester','mothers_height'\n",
    "                                    ,'bmi','prepregnancy_weight','delivery_weight','weight_gain','prepregnancy_diabetes_encoded'\n",
    "                                    ,'gestational_diabetes_encoded','prepregnancy_hypertension_encoded','gestational_hypertension_encoded'\n",
    "                                ,'hypertension_eclampsia_encoded','previous_preterm_birth_encoded','infant_sex_encoded'], outputCol = 'features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.classification as cl\n",
    "logistic = cl.LogisticRegression(\n",
    "                    featuresCol= 'features',\n",
    "                    labelCol ='infant_live_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a simple pipeline\n",
    "pipeline = Pipeline(stages = [feature_pipe, logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(infant_sex_encoded=0, previous_preterm_birth_encoded=0, hypertension_eclampsia_encoded=0, gestational_hypertension_encoded=0, prepregnancy_hypertension_encoded=0, gestational_diabetes_encoded=0, prepregnancy_diabetes_encoded=0, infant_live_encoded=0, birth_place=1, mothers_age=25, fathers_age=25, prental_care=1, cigarettes_before_pregnancy=0, cigarettes_1_trimester=0, cigarettes_2_trimester=0, cigarettes_3_trimester=0, mothers_height=68, bmi=28.700000762939453, prepregnancy_weight=189, delivery_weight=216, weight_gain=27, features=SparseVector(20, {0: 1.0, 1: 25.0, 2: 25.0, 3: 1.0, 8: 68.0, 9: 28.7, 10: 189.0, 11: 216.0, 12: 27.0}), rawPrediction=DenseVector([-7.5138, 7.5138]), probability=DenseVector([0.0005, 0.9995]), prediction=1.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split dataset into training and testing sets\n",
    "births_train, births_test = births_v1.randomSplit([0.75,0.25],seed = 666)\n",
    "#fit and transform \n",
    "model = pipeline.fit(births_train)\n",
    "test_model = model.transform(births_test)\n",
    "#check the model details\n",
    "test_model.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5984844382239075\n",
      "0.999449061898995\n"
     ]
    }
   ],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "#Binary Classification evaluation\n",
    "evaluator = ev.BinaryClassificationEvaluator(\n",
    "                rawPredictionCol = 'probability',\n",
    "                labelCol = 'infant_live_encoded')\n",
    "#rawPredictionCol can be either rawPredictionCol or probability\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 1457\n"
     ]
    }
   ],
   "source": [
    "#As we noticed before, our dataset is imbalanced, so in the following steps, we are goning to fix this issue\n",
    "#step1. make a copy and calculate the label ratio\n",
    "births_v2 = births\n",
    "major_df = births_v2.filter(fn.col(\"infant_live_encoded\")==1)\n",
    "minor_df = births_v2.filter(fn.col(\"infant_live_encoded\")==0)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have two options: oversampling or undersampling\n",
    "#for our project, we tried oversampling:\n",
    "#Oversampling:  duplicate the samples from under-represented class, \n",
    "#to inflate the numbers till it reaches the same level as the dominant class\n",
    "r = range(ratio)\n",
    "## duplicate the minority rows\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", fn.explode(fn.array([fn.lit(x) for x in r]))).drop('dummy')\n",
    "# combine both oversampled minority rows and previous majority rows \n",
    "combined_df = major_df.unionAll(oversampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|infant_live_encoded|  count|\n",
      "+-------------------+-------+\n",
      "|                  1|3224846|\n",
      "|                  0|3224341|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We added the number of target label 0 almost equals to the number of label 1\n",
    "combined_df.groupby('infant_live_encoded').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6160859082989266\n",
      "0.5848010544284474\n"
     ]
    }
   ],
   "source": [
    "#start new pipe to see if oversampling imporve our model performance or not\n",
    "train, test = combined_df.randomSplit([0.75,0.25],seed = 666)\n",
    "model2 = pipeline.fit(train)\n",
    "test_model2 = model.transform(test)\n",
    "#print out the results:\n",
    "print(evaluator.evaluate(test_model2, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(test_model2, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above results show oversampling improve the ROC about 2% and significently decreased our\n",
    "#PR by 41%. Now we are going to do more feature engineering\n",
    "#build vector pipe:\n",
    "vectorizer = ft.VectorAssembler(inputCols=['birth_place', 'mothers_age', 'fathers_age', 'prental_care', 'cigarettes_before_pregnancy', 'cigarettes_1_trimester'\n",
    "                                    ,'cigarettes_2_trimester','cigarettes_3_trimester','mothers_height'\n",
    "                                    ,'bmi','prepregnancy_weight','delivery_weight','weight_gain','prepregnancy_diabetes_encoded'\n",
    "                                    ,'gestational_diabetes_encoded','prepregnancy_hypertension_encoded','gestational_hypertension_encoded'\n",
    "                                ,'hypertension_eclampsia_encoded','previous_preterm_birth_encoded','infant_sex_encoded'], outputCol = 'features')\n",
    "#StandardScaler pipe:\n",
    "normalizer = ft.StandardScaler(\n",
    "                            inputCol = 'features',\n",
    "                            outputCol = 'norm_features',\n",
    "                            withMean = True,\n",
    "                            withStd = True)\n",
    "#build a new lr \n",
    "lr = cl.LogisticRegression(\n",
    "                    maxIter = 10,\n",
    "                    regParam = 0.3,\n",
    "                    elasticNetParam=0.8,\n",
    "                    labelCol ='infant_live_encoded')\n",
    "pipe3 = Pipeline(stages = [vectorizer, normalizer, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = combined_df.randomSplit([0.7,0.2,0.1],seed = 666)\n",
    "lr_model = pipe3.fit(train)\n",
    "val_model = lr_model.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6155965088091023\n",
      "0.584430343629382\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(val_model, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(val_model, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
