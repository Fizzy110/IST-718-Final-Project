{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "#data source: https://data.nber.org/data/vital-statistics-natality-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "labels = [\n",
    "    ('_c0',typ.IntegerType()), #it seems we has to add it here, otherwise the positions of columns would be incorrect\n",
    "    ('birth_place',typ.IntegerType()),\n",
    "    ('mothers_age',typ.IntegerType()),\n",
    "    ('fathers_age',typ.IntegerType()),\n",
    "    ('prental_care',typ.IntegerType()),\n",
    "    ('cigarettes_before_pregnancy',typ.IntegerType()),\n",
    "    ('cigarettes_1_trimester',typ.IntegerType()),\n",
    "    ('cigarettes_2_trimester',typ.IntegerType()),\n",
    "    ('cigarettes_3_trimester',typ.IntegerType()),\n",
    "    ('mothers_height',typ.IntegerType()),\n",
    "    ('bmi',typ.DecimalType()),\n",
    "    ('prepregnancy_weight',typ.DecimalType()), #note: it has be Decimal, otherwise the value will become null\n",
    "    ('delivery_weight',typ.IntegerType()),\n",
    "    ('weight_gain',typ.IntegerType()),\n",
    "    ('prepregnancy_diabetes',typ.StringType()),\n",
    "    ('gestational_diabetes',typ.StringType()),\n",
    "    ('prepregnancy_hypertension',typ.StringType()),\n",
    "    ('gestational_hypertension',typ.StringType()),\n",
    "    ('hypertension_eclampsia',typ.StringType()),\n",
    "    ('previous_preterm_birth',typ.StringType()),\n",
    "    ('infant_sex',typ.StringType()),\n",
    "    ('infant_live',typ.StringType()),\n",
    "]\n",
    "schema = typ.StructType([\n",
    "    typ.StructField(e[0],e[1],False) for e in labels\n",
    "])\n",
    "#This is for databrick\n",
    "#births = spark.read.csv('/FileStore/tables/nat18.csv', header = True, schema = schema)\n",
    "#this is for jupyter:\n",
    "births = spark.read.csv('nat18.csv', header = True, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(births.head(1)) #if the result is False，then the dataset has missing values，otherwise no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = births.filter((births.infant_live != 'U'))\n",
    "births = births.filter((births.prepregnancy_diabetes != 'U'))\n",
    "births = births.filter((births.gestational_diabetes != 'U'))\n",
    "births = births.filter((births.prepregnancy_hypertension != 'U'))\n",
    "births = births.filter((births.gestational_hypertension!= 'U'))\n",
    "births = births.filter((births.hypertension_eclampsia!= 'U'))\n",
    "births = births.filter((births.previous_preterm_birth!= 'U'))\n",
    "births = births.filter((births.fathers_age!= 99))\n",
    "births = births.filter((births.cigarettes_before_pregnancy!= 99))\n",
    "births = births.filter((births.cigarettes_1_trimester!= 99))\n",
    "births = births.filter((births.cigarettes_2_trimester!= 99))\n",
    "births = births.filter((births.cigarettes_3_trimester!= 99))\n",
    "births = births.filter((births.mothers_height!= 99))\n",
    "births = births.filter((births.bmi!= 100))\n",
    "births = births.filter((births.prepregnancy_weight!= 999))\n",
    "births = births.filter((births.delivery_weight!= 999))\n",
    "births = births.filter((births.weight_gain!= 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "births.groupby('infant_live').count().show() #imbalaced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basical dataset statistical check\n",
    "#step1: if the dataset contains duplicate rows:\n",
    "print('Count of rows: {0}'.format(births.count()))\n",
    "print('Count of distinct rows: {0}'.format(births.distinct().count()))\n",
    "#the results show our dataset contains no same rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3: For numerical data, apply the describe() to get statistical summay.\n",
    "numerical = ['mothers_age', 'fathers_age', 'cigarettes_before_pregnancy','cigarettes_1_trimester'\n",
    "            ,'cigarettes_2_trimester','cigarettes_3_trimester','mothers_height','bmi'\n",
    "            ,'prepregnancy_weight','delivery_weight','weight_gain']\n",
    "desc = births.describe(numerical)\n",
    "desc.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering - covert categorical data to dummy variable\n",
    "import pyspark.sql.functions as fn\n",
    "#1.\n",
    "categ = births.select('infant_live').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "exprs = [fn.when(fn.col('infant_live') == Y,1).otherwise(0)\\\n",
    "            .alias(str(Y)) for Y in categ]\n",
    "births = births.select(exprs+births.columns)\n",
    "#drop useless columns and rename target column\n",
    "births = births.drop('N')\n",
    "births = births.drop('_c0')\n",
    "births = births.drop('infant_live')\n",
    "births = births.withColumnRenamed('Y','infant_live_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "births.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mother's age and smoking before pregnancy\n",
    "ax = sns.pairplot(births.toPandas()[['mothers_age','cigarettes_before_pregnancy']])\n",
    "ax.fig.suptitle(\"Vital Data Smoking Pair Plot\", y=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as ft\n",
    "import pyspark.sql.types as typ\n",
    "from pyspark.ml import Pipeline\n",
    "#Feature engineering on categrical data by create multiple pipelines\n",
    "#1.\n",
    "infant_sex_pipe = Pipeline(stages=[ft.StringIndexer(inputCol='infant_sex', handleInvalid='skip',outputCol = \"indexed_sex\"), \n",
    "                                 ft.OneHotEncoder(inputCol='indexed_sex',outputCol = \"infant_sex_encoded\")])\n",
    "#2.\n",
    "prepregnancy_diabetes_pipe = Pipeline(stages=[ft.StringIndexer(inputCol='prepregnancy_diabetes', handleInvalid='skip',outputCol = \"indexed_prepregnancy_diabetes\"), \n",
    "    ft.OneHotEncoder(inputCol='indexed_prepregnancy_diabetes',outputCol = \"prepregnancy_diabetes_encoded\")])\n",
    "#3.\n",
    "gestational_diabetes_pipe = Pipeline(stages=[ft.StringIndexer(inputCol='gestational_diabetes', handleInvalid='skip',outputCol = \"indexed_gestational_diabetes\"), \n",
    "    ft.OneHotEncoder(inputCol='indexed_gestational_diabetes',outputCol = \"gestational_diabetes_encoded\")])\n",
    "#4.\n",
    "prepregnancy_hypertension_pipe = Pipeline(stages=[ft.StringIndexer(inputCol='prepregnancy_hypertension', handleInvalid='skip',outputCol = \"indexed_prepregnancy_hypertension\"), \n",
    "    ft.OneHotEncoder(inputCol='indexed_prepregnancy_hypertension',outputCol = \"prepregnancy_hypertension_encoded\")])\n",
    "#5.\n",
    "gestational_hypertension_pipe = Pipeline(stages=[ft.StringIndexer(inputCol='gestational_hypertension', handleInvalid='skip',outputCol = \"indexed_gestational_hypertension\"), \n",
    "    ft.OneHotEncoder(inputCol='indexed_gestational_hypertension',outputCol = \"gestational_hypertension_encoded\")])\n",
    "#6.\n",
    "hypertension_eclampsia_pipe = Pipeline(stages=[ft.StringIndexer(inputCol='hypertension_eclampsia', handleInvalid='skip',outputCol = \"indexed_hypertension_eclampsia\"), \n",
    "    ft.OneHotEncoder(inputCol='indexed_hypertension_eclampsia',outputCol = \"hypertension_eclampsia_encoded\")])\n",
    "#7.\n",
    "previous_preterm_birth_pipe = Pipeline(stages=[ft.StringIndexer(inputCol='previous_preterm_birth', handleInvalid='skip',outputCol = \"indexed_previous_preterm_birth\"), \n",
    "    ft.OneHotEncoder(inputCol='indexed_previous_preterm_birth',outputCol = \"previous_preterm_birth_encoded\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering on numerical data by create multiple pipelines\n",
    "numerical_pipe = Pipeline(stages = [ft.VectorAssembler(inputCols=['birth_place', 'mothers_age', 'fathers_age', 'prental_care', 'cigarettes_before_pregnancy', 'cigarettes_1_trimester'\n",
    "                                    ,'cigarettes_2_trimester','cigarettes_3_trimester','mothers_height'\n",
    "                                    ,'bmi','prepregnancy_weight','delivery_weight','weight_gain'], outputCol = 'num_features'),\n",
    "                                   ft.StandardScaler(inputCol=\"num_features\", outputCol=\"scaledFeatures\")])                                 \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip string pipe and numeric pipe\n",
    "all_features = Pipeline(stages = [numerical_pipe,\n",
    "                                 infant_sex_pipe,\n",
    "                                 prepregnancy_diabetes_pipe,\n",
    "                                 gestational_diabetes_pipe,\n",
    "                                 prepregnancy_hypertension_pipe,\n",
    "                                 gestational_hypertension_pipe,\n",
    "                                 hypertension_eclampsia_pipe,\n",
    "                                 previous_preterm_birth_pipe,\n",
    "                                 ft.VectorAssembler(inputCols = ['scaledFeatures',\n",
    "                                                                'infant_sex_encoded',\n",
    "                                                                'prepregnancy_diabetes_encoded',\n",
    "                                                                'gestational_diabetes_encoded',\n",
    "                                                                'prepregnancy_hypertension_encoded',\n",
    "                                                                'gestational_hypertension_encoded',\n",
    "                                                                'hypertension_eclampsia_encoded',\n",
    "                                                                'previous_preterm_birth_encoded'],\n",
    "                                                   outputCol = 'features')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a logistic regression model\n",
    "import pyspark.ml.classification as cl\n",
    "logistic = cl.LogisticRegression(labelCol ='infant_live_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a simple pipeline\n",
    "pipeline = Pipeline(stages = [all_features, logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_v1 = births\n",
    "#split dataset into training and testing sets\n",
    "births_train, births_val, births_test = births_v1.randomSplit([0.7,0.2,0.1],seed = 666)\n",
    "#fit and transform \n",
    "model = pipeline.fit(births_train)\n",
    "test_model = model.transform(births_val)\n",
    "#check the model details\n",
    "test_model.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "#Binary Classification evaluation\n",
    "evaluator = ev.BinaryClassificationEvaluator(\n",
    "                rawPredictionCol = 'probability',\n",
    "                labelCol = 'infant_live_encoded')\n",
    "#rawPredictionCol can be either rawPredictionCol or probability\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(test_model, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Accuracy rate:\n",
    "test_model.select(fn.avg(fn.expr('prediction = infant_live_encoded ').cast('float'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_v2 = births\n",
    "major_df = births_v2.filter(fn.col(\"infant_live_encoded\")==1)\n",
    "minor_df = births_v2.filter(fn.col(\"infant_live_encoded\")==0)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the ratio and the dataset size are fairly large, we decided to perform undersampling:\n",
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "combined_df = sampled_majority_df.unionAll(minor_df)\n",
    "combined_df.groupby('infant_live_encoded').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the undersampling dataset performance\n",
    "train, val, test = combined_df.randomSplit([0.7,0.2,0.1],seed = 666)\n",
    "model2 = pipeline.fit(train)\n",
    "test_model2 = model.transform(val)\n",
    "#print out the results:\n",
    "print(evaluator.evaluate(test_model2, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(test_model2, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model2.select(fn.avg(fn.expr('prediction = infant_live_encoded ').cast('float'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It seems undersampling dropped our model performance, therefore we will just go with the orignial \n",
    "#dataset in the future.\n",
    "#build a new pipeline for grid search\n",
    "#1.numerical data\n",
    "numerical_pipe2 = Pipeline(stages = [ft.VectorAssembler(inputCols=['birth_place', 'mothers_age', 'fathers_age', 'prental_care', 'cigarettes_before_pregnancy', 'cigarettes_1_trimester'\n",
    "                                    ,'cigarettes_2_trimester','cigarettes_3_trimester','mothers_height'\n",
    "                                    ,'bmi','prepregnancy_weight','delivery_weight','weight_gain'], outputCol = 'num_features'),\n",
    "                                   ft.StandardScaler(inputCol=\"num_features\", outputCol=\"scaledFeatures\",withMean = True, withStd = True)]) \n",
    "#\n",
    "all_features2 = Pipeline(stages = [numerical_pipe2,\n",
    "                                 infant_sex_pipe,\n",
    "                                 prepregnancy_diabetes_pipe,\n",
    "                                 gestational_diabetes_pipe,\n",
    "                                 prepregnancy_hypertension_pipe,\n",
    "                                 gestational_hypertension_pipe,\n",
    "                                 hypertension_eclampsia_pipe,\n",
    "                                 previous_preterm_birth_pipe,\n",
    "                                 ft.VectorAssembler(inputCols = ['scaledFeatures',\n",
    "                                                                'infant_sex_encoded',\n",
    "                                                                'prepregnancy_diabetes_encoded',\n",
    "                                                                'gestational_diabetes_encoded',\n",
    "                                                                'prepregnancy_hypertension_encoded',\n",
    "                                                                'gestational_hypertension_encoded',\n",
    "                                                                'hypertension_eclampsia_encoded',\n",
    "                                                                'previous_preterm_birth_encoded'],\n",
    "                                                   outputCol = 'features')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning as tune\n",
    "lr = cl.LogisticRegression(labelCol ='infant_live_encoded')\n",
    "\n",
    "grid = tune.ParamGridBuilder().addGrid(lr.maxIter,[2,5,10])\\\n",
    "                              .addGrid(lr.regParam,[0.01,0.05,0.3])\\\n",
    "                              .addGrid(lr.elasticNetParam,[0.2,0.5,0.8])\\\n",
    "                              .build()\n",
    "evaluator = ev.BinaryClassificationEvaluator(\n",
    "                rawPredictionCol = 'probability',\n",
    "                labelCol = 'infant_live_encoded')\n",
    "cv = tune.CrossValidator(\n",
    "                estimator = lr,\n",
    "                estimatorParamMaps = grid,\n",
    "                evaluator = evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = all_features2.fit(births_train)\n",
    "cvModel = cv.fit(data_transformer.transform(births_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the cv model results:\n",
    "data_train = data_transformer.transform(births_test)\n",
    "results = cvModel.transform(data_train)\n",
    "print(evaluator.evaluate(results,{evaluator.metricName:'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results,{evaluator.metricName:'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handyspark import *\n",
    "bcm = BinaryClassificationMetrics(data_train, scoreCol='probability', labelCol='infant_live_encoded')\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "bcm.plot_roc_curve(ax=axs[0])\n",
    "bcm.plot_pr_curve(ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the best model hyperparameters:\n",
    "results = [\n",
    "  (\n",
    "  [\n",
    "    {key.name:paramValue}\n",
    "    for key, paramValue in zip(params.keys(),params.values())\n",
    "  ],metric)\n",
    "  for params, metric in zip(cvModel.getEstimatorParamMaps(),\n",
    "                            cvModel.avgMetrics)\n",
    "]\n",
    "sorted(results, key = lambda e1:e1[1],\n",
    "      reverse = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#second model: random forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "IST718 Final Project",
  "notebookId": 13073513834775
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
